{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZZpOHZExcMw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arnaldochm/Documents/BootCamp_DataScience/Final_Project/final_project_nlp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-11-02 22:41:50.564043: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-02 22:41:50.566311: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-02 22:41:50.603289: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-02 22:41:50.604671: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-02 22:41:51.318398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Step 0. Load libraries and custom modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "# ------------  PREPROCESING -------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "#-------------- TRANSFORMERS --------------\n",
        "import transformers\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "from transformers import Conversation\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx0-j5xbxcMx",
        "outputId": "8fde96c4-b40b-4503-91f2-83b620613f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 552639 entries, 0 to 552638\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  552639 non-null  int64 \n",
            " 1   num_row     552639 non-null  int64 \n",
            " 2   text        552639 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 12.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df_reduced = pd.read_csv('../data/processed/df_reduced.csv')\n",
        "df_reduced.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hI-V-oHmxcMy"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['Unnamed: 0'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AJnhviSgxcMy",
        "outputId": "642af037-c9b0-43f7-f053-e1bd64234f83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12431</th>\n",
              "      <td>12431</td>\n",
              "      <td>Animal Farm is a book I'm not used to reading....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133978</th>\n",
              "      <td>133978</td>\n",
              "      <td>When Sarah Thomas and Sophia Rizzo are working...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418692</th>\n",
              "      <td>418692</td>\n",
              "      <td>Sometimes it pays to re read the books you HAD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534445</th>\n",
              "      <td>534445</td>\n",
              "      <td>I found this very informative. It is very well...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143126</th>\n",
              "      <td>143126</td>\n",
              "      <td>Absolutely wonderful reading, you'll never los...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448841</th>\n",
              "      <td>448841</td>\n",
              "      <td>This was a book that really built my love of A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521131</th>\n",
              "      <td>521131</td>\n",
              "      <td>After reading \"Interview\" I was mesmerized abo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257631</th>\n",
              "      <td>257631</td>\n",
              "      <td>I was required to read &amp;quot;The Jungle&amp;quot; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513634</th>\n",
              "      <td>513634</td>\n",
              "      <td>The story was told by an experienced storytell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541998</th>\n",
              "      <td>541998</td>\n",
              "      <td>In his second of three books, 'GO-KYU: Princip...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                               text\n",
              "12431     12431  Animal Farm is a book I'm not used to reading....\n",
              "133978   133978  When Sarah Thomas and Sophia Rizzo are working...\n",
              "418692   418692  Sometimes it pays to re read the books you HAD...\n",
              "534445   534445  I found this very informative. It is very well...\n",
              "143126   143126  Absolutely wonderful reading, you'll never los...\n",
              "448841   448841  This was a book that really built my love of A...\n",
              "521131   521131  After reading \"Interview\" I was mesmerized abo...\n",
              "257631   257631  I was required to read &quot;The Jungle&quot; ...\n",
              "513634   513634  The story was told by an experienced storytell...\n",
              "541998   541998  In his second of three books, 'GO-KYU: Princip..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QLcrOVQCSvV",
        "outputId": "56ad309f-5ba2-4ed4-9720-2c7fafdebe70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TnFxeo9YCd1n"
      },
      "outputs": [],
      "source": [
        "def clean_stopwords(text: str,stop_dict: dict)->str:\n",
        "    if text is not None:\n",
        "        words = text.split()\n",
        "        words_clean = []\n",
        "        for word in words:\n",
        "            if word not in stop_dict:\n",
        "                words_clean.append(word)\n",
        "        result = ' '.join(words_clean)\n",
        "    else:\n",
        "        result = None\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OaZQCL1hCHjS"
      },
      "outputs": [],
      "source": [
        "# 3.10 Process text to extract stopwords\n",
        "df_reduced['text_clean'] = df_reduced['text'].str.lower()\n",
        "stop_dict = stopwords.words('english')\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].apply(lambda x: clean_stopwords(x, stop_dict = stop_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z8J38661CzTx"
      },
      "outputs": [],
      "source": [
        "# 3.12 Extract special characters\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'''[!.,():\\-%$/'\"‘]''', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rObXY_twC7C3"
      },
      "outputs": [],
      "source": [
        "# 3.13 Extract numbers\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'[\\d]+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UDVhJZmmJWPM"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['text'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lvYNEGJPDjLI",
        "outputId": "b9b25394-1a28-4218-c34f-37341d001f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>someone know receives diagnosis prostate cance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>simple point chalk full information herbs uses...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>read book day &amp; half interesting reading belie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>bought book biological anthropology class text...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>slaughterhouse  slaughterhouse five childrens ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean\n",
              "0        0  pretty good book clear content say something r...\n",
              "1        1  terry pratchetts first novel the carpet people...\n",
              "2        2  must around  capable artist basil hallward bri...\n",
              "3        3  first read book early teens reread fourth time...\n",
              "4        4  patrick kelsey learns woman replace retired co...\n",
              "5        5  someone know receives diagnosis prostate cance...\n",
              "6        6  simple point chalk full information herbs uses...\n",
              "7        7  read book day & half interesting reading belie...\n",
              "8        8  bought book biological anthropology class text...\n",
              "9        9  slaughterhouse  slaughterhouse five childrens ..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3.14 See the results\n",
        "df_reduced.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaderSentimentAnalyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.162, 'neu': 0.568, 'pos': 0.27, 'compound': 0.7579}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vaderSentimentAnalyzer.polarity_scores(df_reduced.iloc[67]['text_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "      <td>{'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "      <td>{'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "      <td>{'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "      <td>{'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "      <td>{'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  pretty good book clear content say something r...   \n",
              "1        1  terry pratchetts first novel the carpet people...   \n",
              "2        2  must around  capable artist basil hallward bri...   \n",
              "3        3  first read book early teens reread fourth time...   \n",
              "4        4  patrick kelsey learns woman replace retired co...   \n",
              "\n",
              "                                              scores  \n",
              "0  {'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...  \n",
              "1  {'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...  \n",
              "2  {'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...  \n",
              "3  {'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...  \n",
              "4  {'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['scores']=df_reduced['text_clean'].apply(lambda body: vaderSentimentAnalyzer.polarity_scores(str(body)))\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "      <td>{'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...</td>\n",
              "      <td>0.9948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "      <td>{'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...</td>\n",
              "      <td>0.9823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "      <td>{'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...</td>\n",
              "      <td>0.9970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "      <td>{'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...</td>\n",
              "      <td>0.1280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "      <td>{'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...</td>\n",
              "      <td>0.4624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  pretty good book clear content say something r...   \n",
              "1        1  terry pratchetts first novel the carpet people...   \n",
              "2        2  must around  capable artist basil hallward bri...   \n",
              "3        3  first read book early teens reread fourth time...   \n",
              "4        4  patrick kelsey learns woman replace retired co...   \n",
              "\n",
              "                                              scores  compound_sentiment  \n",
              "0  {'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...              0.9948  \n",
              "1  {'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...              0.9823  \n",
              "2  {'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...              0.9970  \n",
              "3  {'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...              0.1280  \n",
              "4  {'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...              0.4624  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['compound_sentiment']=df_reduced['scores'].apply(lambda score_dict:score_dict['compound'])\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_reduced['sentiment']=''\n",
        "# df_reduced.loc[df_reduced.compound>0,'sentiment']='POS'\n",
        "# df_reduced.loc[df_reduced.compound==0,'sentiment']='NEUTRAL'\n",
        "# df_reduced.loc[df_reduced.compound<0,'sentiment']='NEG'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>239503</th>\n",
              "      <td>239503</td>\n",
              "      <td>naked death another success jd robb continuing...</td>\n",
              "      <td>0.2718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180568</th>\n",
              "      <td>180568</td>\n",
              "      <td>bill bailey makes audio cassette version come ...</td>\n",
              "      <td>0.8479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95558</th>\n",
              "      <td>95558</td>\n",
              "      <td>ready really get serious character development...</td>\n",
              "      <td>0.4976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461754</th>\n",
              "      <td>461754</td>\n",
              "      <td>[] []and love book infact one favorites ophie ...</td>\n",
              "      <td>0.9775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253021</th>\n",
              "      <td>253021</td>\n",
              "      <td>veteran dozen books africa quite likely finest...</td>\n",
              "      <td>0.7717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383420</th>\n",
              "      <td>383420</td>\n",
              "      <td>read naturalist recently finished the social c...</td>\n",
              "      <td>0.9432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427497</th>\n",
              "      <td>427497</td>\n",
              "      <td>spirits strengh lifted momentary warmth stood ...</td>\n",
              "      <td>0.9545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435869</th>\n",
              "      <td>435869</td>\n",
              "      <td>emma woodhouse handsome clever rich comfortabl...</td>\n",
              "      <td>0.9988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227822</th>\n",
              "      <td>227822</td>\n",
              "      <td>failure appear lonewolf seattle homicide detec...</td>\n",
              "      <td>-0.9776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226825</th>\n",
              "      <td>226825</td>\n",
              "      <td>perhaps first book ive read deals remnants lon...</td>\n",
              "      <td>0.6124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                         text_clean  \\\n",
              "239503   239503  naked death another success jd robb continuing...   \n",
              "180568   180568  bill bailey makes audio cassette version come ...   \n",
              "95558     95558  ready really get serious character development...   \n",
              "461754   461754  [] []and love book infact one favorites ophie ...   \n",
              "253021   253021  veteran dozen books africa quite likely finest...   \n",
              "383420   383420  read naturalist recently finished the social c...   \n",
              "427497   427497  spirits strengh lifted momentary warmth stood ...   \n",
              "435869   435869  emma woodhouse handsome clever rich comfortabl...   \n",
              "227822   227822  failure appear lonewolf seattle homicide detec...   \n",
              "226825   226825  perhaps first book ive read deals remnants lon...   \n",
              "\n",
              "        compound_sentiment  \n",
              "239503              0.2718  \n",
              "180568              0.8479  \n",
              "95558               0.4976  \n",
              "461754              0.9775  \n",
              "253021              0.7717  \n",
              "383420              0.9432  \n",
              "427497              0.9545  \n",
              "435869              0.9988  \n",
              "227822             -0.9776  \n",
              "226825              0.6124  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced = df_reduced.drop(['scores'], axis=1)\n",
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reduced.to_csv('../data/processed/df_reduced_with_sentiment.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
