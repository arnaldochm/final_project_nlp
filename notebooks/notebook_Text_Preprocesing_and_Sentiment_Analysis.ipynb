{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZZpOHZExcMw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arnaldochm/Documents/BootCamp_DataScience/Final_Project/final_project_nlp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-11-06 23:46:59.035116: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-06 23:46:59.046564: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-06 23:46:59.130923: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-06 23:46:59.131982: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-06 23:47:00.474790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Step 0. Load libraries and custom modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "# ------------  PREPROCESING -------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "#-------------- TRANSFORMERS --------------\n",
        "import transformers\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "from transformers import Conversation\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx0-j5xbxcMx",
        "outputId": "8fde96c4-b40b-4503-91f2-83b620613f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15425 entries, 0 to 15424\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  15425 non-null  int64 \n",
            " 1   num_row     15425 non-null  int64 \n",
            " 2   text        15425 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 361.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df_reduced = pd.read_csv('../data/processed/df_reduced.csv')\n",
        "df_reduced.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hI-V-oHmxcMy"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['Unnamed: 0'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AJnhviSgxcMy",
        "outputId": "642af037-c9b0-43f7-f053-e1bd64234f83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5027</th>\n",
              "      <td>5027</td>\n",
              "      <td>This was my first 'Kindle' read and I loved it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7461</th>\n",
              "      <td>7461</td>\n",
              "      <td>Mr. Coates does professional-sounding arrangem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5948</th>\n",
              "      <td>5948</td>\n",
              "      <td>Turns out my code was used 4 years ago. Don't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>We were so happy with the Curious George book,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6235</th>\n",
              "      <td>6235</td>\n",
              "      <td>I have not finished the book yet, but far enou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>1978</td>\n",
              "      <td>Translating the Message can be seen as a long ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7582</th>\n",
              "      <td>7582</td>\n",
              "      <td>I bought this book for one of my Life Skills s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>909</td>\n",
              "      <td>Ordered this book and item was shipped next da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14357</th>\n",
              "      <td>14357</td>\n",
              "      <td>I would recommend this product, very useful fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8767</th>\n",
              "      <td>8767</td>\n",
              "      <td>I would recommend reading the series in order....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       num_row                                               text\n",
              "5027      5027  This was my first 'Kindle' read and I loved it...\n",
              "7461      7461  Mr. Coates does professional-sounding arrangem...\n",
              "5948      5948  Turns out my code was used 4 years ago. Don't ...\n",
              "63          63  We were so happy with the Curious George book,...\n",
              "6235      6235  I have not finished the book yet, but far enou...\n",
              "1978      1978  Translating the Message can be seen as a long ...\n",
              "7582      7582  I bought this book for one of my Life Skills s...\n",
              "909        909  Ordered this book and item was shipped next da...\n",
              "14357    14357  I would recommend this product, very useful fo...\n",
              "8767      8767  I would recommend reading the series in order...."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QLcrOVQCSvV",
        "outputId": "56ad309f-5ba2-4ed4-9720-2c7fafdebe70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TnFxeo9YCd1n"
      },
      "outputs": [],
      "source": [
        "def clean_stopwords(text: str,stop_dict: dict)->str:\n",
        "    if text is not None:\n",
        "        words = text.split()\n",
        "        words_clean = []\n",
        "        for word in words:\n",
        "            if word not in stop_dict:\n",
        "                words_clean.append(word)\n",
        "        result = ' '.join(words_clean)\n",
        "    else:\n",
        "        result = None\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OaZQCL1hCHjS"
      },
      "outputs": [],
      "source": [
        "# 3.10 Process text to extract stopwords\n",
        "df_reduced['text_clean'] = df_reduced['text'].str.lower()\n",
        "stop_dict = stopwords.words('english')\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].apply(lambda x: clean_stopwords(x, stop_dict = stop_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z8J38661CzTx"
      },
      "outputs": [],
      "source": [
        "# 3.12 Extract special characters\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'''[!.,():\\-%$/'\"â€˜]''', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rObXY_twC7C3"
      },
      "outputs": [],
      "source": [
        "# 3.13 Extract numbers\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'[\\d]+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UDVhJZmmJWPM"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['text'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lvYNEGJPDjLI",
        "outputId": "b9b25394-1a28-4218-c34f-37341d001f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>odyssey two strong sequel arthur c clarkes r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>faith faith devotional awesome book quite insp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>first reading book absolutely last also read s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>book explores death penalty delves lot misconc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>finally printondemand book actually looks like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>normally enjoy contemporary romances much litt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>barbara vine marvelous author ruth rendell vin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>reflect closing  year old daughters rd grade y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>think book gonna read like dan brown book gonn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>read series long kindles loved them eight inte...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean\n",
              "0        0    odyssey two strong sequel arthur c clarkes r...\n",
              "1        1  faith faith devotional awesome book quite insp...\n",
              "2        2  first reading book absolutely last also read s...\n",
              "3        3  book explores death penalty delves lot misconc...\n",
              "4        4  finally printondemand book actually looks like...\n",
              "5        5  normally enjoy contemporary romances much litt...\n",
              "6        6  barbara vine marvelous author ruth rendell vin...\n",
              "7        7  reflect closing  year old daughters rd grade y...\n",
              "8        8  think book gonna read like dan brown book gonn...\n",
              "9        9  read series long kindles loved them eight inte..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3.14 See the results\n",
        "df_reduced.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaderSentimentAnalyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.097, 'neu': 0.714, 'pos': 0.19, 'compound': 0.9058}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vaderSentimentAnalyzer.polarity_scores(df_reduced.iloc[67]['text_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>odyssey two strong sequel arthur c clarkes r...</td>\n",
              "      <td>{'neg': 0.067, 'neu': 0.734, 'pos': 0.199, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>faith faith devotional awesome book quite insp...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.381, 'pos': 0.619, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>first reading book absolutely last also read s...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>book explores death penalty delves lot misconc...</td>\n",
              "      <td>{'neg': 0.338, 'neu': 0.611, 'pos': 0.052, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>finally printondemand book actually looks like...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.599, 'pos': 0.401, 'comp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0    odyssey two strong sequel arthur c clarkes r...   \n",
              "1        1  faith faith devotional awesome book quite insp...   \n",
              "2        2  first reading book absolutely last also read s...   \n",
              "3        3  book explores death penalty delves lot misconc...   \n",
              "4        4  finally printondemand book actually looks like...   \n",
              "\n",
              "                                              scores  \n",
              "0  {'neg': 0.067, 'neu': 0.734, 'pos': 0.199, 'co...  \n",
              "1  {'neg': 0.0, 'neu': 0.381, 'pos': 0.619, 'comp...  \n",
              "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
              "3  {'neg': 0.338, 'neu': 0.611, 'pos': 0.052, 'co...  \n",
              "4  {'neg': 0.0, 'neu': 0.599, 'pos': 0.401, 'comp...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['scores']=df_reduced['text_clean'].apply(lambda body: vaderSentimentAnalyzer.polarity_scores(str(body)))\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>odyssey two strong sequel arthur c clarkes r...</td>\n",
              "      <td>{'neg': 0.067, 'neu': 0.734, 'pos': 0.199, 'co...</td>\n",
              "      <td>0.9956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>faith faith devotional awesome book quite insp...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.381, 'pos': 0.619, 'comp...</td>\n",
              "      <td>0.9643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>first reading book absolutely last also read s...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>book explores death penalty delves lot misconc...</td>\n",
              "      <td>{'neg': 0.338, 'neu': 0.611, 'pos': 0.052, 'co...</td>\n",
              "      <td>-0.9432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>finally printondemand book actually looks like...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.599, 'pos': 0.401, 'comp...</td>\n",
              "      <td>0.9081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0    odyssey two strong sequel arthur c clarkes r...   \n",
              "1        1  faith faith devotional awesome book quite insp...   \n",
              "2        2  first reading book absolutely last also read s...   \n",
              "3        3  book explores death penalty delves lot misconc...   \n",
              "4        4  finally printondemand book actually looks like...   \n",
              "\n",
              "                                              scores  compound_sentiment  \n",
              "0  {'neg': 0.067, 'neu': 0.734, 'pos': 0.199, 'co...              0.9956  \n",
              "1  {'neg': 0.0, 'neu': 0.381, 'pos': 0.619, 'comp...              0.9643  \n",
              "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...              0.0000  \n",
              "3  {'neg': 0.338, 'neu': 0.611, 'pos': 0.052, 'co...             -0.9432  \n",
              "4  {'neg': 0.0, 'neu': 0.599, 'pos': 0.401, 'comp...              0.9081  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['compound_sentiment']=df_reduced['scores'].apply(lambda score_dict:score_dict['compound'])\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>801</td>\n",
              "      <td>arthurs writing book excellent like plots stor...</td>\n",
              "      <td>0.9451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2941</th>\n",
              "      <td>2941</td>\n",
              "      <td>like read excentrics great bookthe tenacity ad...</td>\n",
              "      <td>0.5267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4837</th>\n",
              "      <td>4837</td>\n",
              "      <td>figured price classic good cover would typical...</td>\n",
              "      <td>0.8689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1604</th>\n",
              "      <td>1604</td>\n",
              "      <td>saseks books visually lovely doubt it however ...</td>\n",
              "      <td>0.9907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4024</th>\n",
              "      <td>4024</td>\n",
              "      <td>book arrived student ready bible dog retrainin...</td>\n",
              "      <td>0.1027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14499</th>\n",
              "      <td>14499</td>\n",
              "      <td>read book couple years ago great intriguing re...</td>\n",
              "      <td>0.7783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7638</th>\n",
              "      <td>7638</td>\n",
              "      <td>book outstanding written stand see one review ...</td>\n",
              "      <td>0.9300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8789</th>\n",
              "      <td>8789</td>\n",
              "      <td>read one book life twice  make one read twice ...</td>\n",
              "      <td>-0.5994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12457</th>\n",
              "      <td>12457</td>\n",
              "      <td>read book the name rose years ago first publis...</td>\n",
              "      <td>0.9524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9294</th>\n",
              "      <td>9294</td>\n",
              "      <td>maier managed write story true roots yet also ...</td>\n",
              "      <td>0.8402</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       num_row                                         text_clean  \\\n",
              "801        801  arthurs writing book excellent like plots stor...   \n",
              "2941      2941  like read excentrics great bookthe tenacity ad...   \n",
              "4837      4837  figured price classic good cover would typical...   \n",
              "1604      1604  saseks books visually lovely doubt it however ...   \n",
              "4024      4024  book arrived student ready bible dog retrainin...   \n",
              "14499    14499  read book couple years ago great intriguing re...   \n",
              "7638      7638  book outstanding written stand see one review ...   \n",
              "8789      8789  read one book life twice  make one read twice ...   \n",
              "12457    12457  read book the name rose years ago first publis...   \n",
              "9294      9294  maier managed write story true roots yet also ...   \n",
              "\n",
              "       compound_sentiment  \n",
              "801                0.9451  \n",
              "2941               0.5267  \n",
              "4837               0.8689  \n",
              "1604               0.9907  \n",
              "4024               0.1027  \n",
              "14499              0.7783  \n",
              "7638               0.9300  \n",
              "8789              -0.5994  \n",
              "12457              0.9524  \n",
              "9294               0.8402  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced = df_reduced.drop(['scores'], axis=1)\n",
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reduced.to_csv('../data/processed/df_reduced_with_sentiment.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
