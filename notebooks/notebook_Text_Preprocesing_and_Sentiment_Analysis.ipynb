{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZZpOHZExcMw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arnaldochm/Documents/BootCamp_DataScience/Final_Project/final_project_nlp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-11-01 06:03:34.167719: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-01 06:03:34.169916: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-01 06:03:34.207422: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-01 06:03:34.208052: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-01 06:03:34.982866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Step 0. Load libraries and custom modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "# ------------  PREPROCESING -------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "#-------------- TRANSFORMERS --------------\n",
        "import transformers\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "from transformers import Conversation\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx0-j5xbxcMx",
        "outputId": "8fde96c4-b40b-4503-91f2-83b620613f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 339619 entries, 0 to 339618\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  339619 non-null  int64 \n",
            " 1   num_row     339619 non-null  int64 \n",
            " 2   text        339619 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 7.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df_reduced = pd.read_csv('../data/processed/df_reduced.csv')\n",
        "df_reduced.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hI-V-oHmxcMy"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['Unnamed: 0'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AJnhviSgxcMy",
        "outputId": "642af037-c9b0-43f7-f053-e1bd64234f83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134398</th>\n",
              "      <td>134398</td>\n",
              "      <td>I wish I could give this zero stars. My daught...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120553</th>\n",
              "      <td>120553</td>\n",
              "      <td>I'm going to try to keep this short and sweet,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335777</th>\n",
              "      <td>335777</td>\n",
              "      <td>I re-read this book because I wanted to go and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195261</th>\n",
              "      <td>195261</td>\n",
              "      <td>This book was very entertaining but incredibly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294833</th>\n",
              "      <td>294833</td>\n",
              "      <td>When reading the other reviews on this site fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82982</th>\n",
              "      <td>82982</td>\n",
              "      <td>No one can compare with Bram Stoker's Dracula ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173650</th>\n",
              "      <td>173650</td>\n",
              "      <td>I was supposed to read this book in high schoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41597</th>\n",
              "      <td>41597</td>\n",
              "      <td>The setting is in a furturistic society where ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194824</th>\n",
              "      <td>194824</td>\n",
              "      <td>Tolkien set the background of Heroic Fantasy (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268867</th>\n",
              "      <td>268867</td>\n",
              "      <td>This is not a light read- but you will remembe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                               text\n",
              "134398   134398  I wish I could give this zero stars. My daught...\n",
              "120553   120553  I'm going to try to keep this short and sweet,...\n",
              "335777   335777  I re-read this book because I wanted to go and...\n",
              "195261   195261  This book was very entertaining but incredibly...\n",
              "294833   294833  When reading the other reviews on this site fo...\n",
              "82982     82982  No one can compare with Bram Stoker's Dracula ...\n",
              "173650   173650  I was supposed to read this book in high schoo...\n",
              "41597     41597  The setting is in a furturistic society where ...\n",
              "194824   194824  Tolkien set the background of Heroic Fantasy (...\n",
              "268867   268867  This is not a light read- but you will remembe..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QLcrOVQCSvV",
        "outputId": "56ad309f-5ba2-4ed4-9720-2c7fafdebe70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TnFxeo9YCd1n"
      },
      "outputs": [],
      "source": [
        "def clean_stopwords(text: str,stop_dict: dict)->str:\n",
        "    if text is not None:\n",
        "        words = text.split()\n",
        "        words_clean = []\n",
        "        for word in words:\n",
        "            if word not in stop_dict:\n",
        "                words_clean.append(word)\n",
        "        result = ' '.join(words_clean)\n",
        "    else:\n",
        "        result = None\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OaZQCL1hCHjS"
      },
      "outputs": [],
      "source": [
        "# 3.10 Process text to extract stopwords\n",
        "df_reduced['text_clean'] = df_reduced['text'].str.lower()\n",
        "stop_dict = stopwords.words('english')\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].apply(lambda x: clean_stopwords(x, stop_dict = stop_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z8J38661CzTx"
      },
      "outputs": [],
      "source": [
        "# 3.12 Extract special characters\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'''[!.,():\\-%$/'\"â€˜]''', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rObXY_twC7C3"
      },
      "outputs": [],
      "source": [
        "# 3.13 Extract numbers\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'[\\d]+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UDVhJZmmJWPM"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['text'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lvYNEGJPDjLI",
        "outputId": "b9b25394-1a28-4218-c34f-37341d001f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>matter many times read book impossible get tir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>avid scifi fan ive read many books genere foun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>foundation truly one greatest science fiction ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>spectacular universe created issac asimov foun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>think book read every fanatic science fictioni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>think isaac must robot human could possibly am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>foundation series still classic must read ever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>foundation novels great pleasureto read surpri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>foundation nut given  issac asimovs foundatino...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>one asimovs early masterpieces however would r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean\n",
              "0        0  matter many times read book impossible get tir...\n",
              "1        1  avid scifi fan ive read many books genere foun...\n",
              "2        2  foundation truly one greatest science fiction ...\n",
              "3        3  spectacular universe created issac asimov foun...\n",
              "4        4  think book read every fanatic science fictioni...\n",
              "5        5  think isaac must robot human could possibly am...\n",
              "6        6  foundation series still classic must read ever...\n",
              "7        7  foundation novels great pleasureto read surpri...\n",
              "8        8  foundation nut given  issac asimovs foundatino...\n",
              "9        9  one asimovs early masterpieces however would r..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3.14 See the results\n",
        "df_reduced.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaderSentimentAnalyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.057, 'neu': 0.657, 'pos': 0.286, 'compound': 0.9953}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vaderSentimentAnalyzer.polarity_scores(df_reduced.iloc[67]['text_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>matter many times read book impossible get tir...</td>\n",
              "      <td>{'neg': 0.075, 'neu': 0.517, 'pos': 0.408, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>avid scifi fan ive read many books genere foun...</td>\n",
              "      <td>{'neg': 0.066, 'neu': 0.471, 'pos': 0.464, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>foundation truly one greatest science fiction ...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.478, 'pos': 0.522, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>spectacular universe created issac asimov foun...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.661, 'pos': 0.245, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>think book read every fanatic science fictioni...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  matter many times read book impossible get tir...   \n",
              "1        1  avid scifi fan ive read many books genere foun...   \n",
              "2        2  foundation truly one greatest science fiction ...   \n",
              "3        3  spectacular universe created issac asimov foun...   \n",
              "4        4  think book read every fanatic science fictioni...   \n",
              "\n",
              "                                              scores  \n",
              "0  {'neg': 0.075, 'neu': 0.517, 'pos': 0.408, 'co...  \n",
              "1  {'neg': 0.066, 'neu': 0.471, 'pos': 0.464, 'co...  \n",
              "2  {'neg': 0.0, 'neu': 0.478, 'pos': 0.522, 'comp...  \n",
              "3  {'neg': 0.094, 'neu': 0.661, 'pos': 0.245, 'co...  \n",
              "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['scores']=df_reduced['text_clean'].apply(lambda body: vaderSentimentAnalyzer.polarity_scores(str(body)))\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>matter many times read book impossible get tir...</td>\n",
              "      <td>{'neg': 0.075, 'neu': 0.517, 'pos': 0.408, 'co...</td>\n",
              "      <td>0.9169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>avid scifi fan ive read many books genere foun...</td>\n",
              "      <td>{'neg': 0.066, 'neu': 0.471, 'pos': 0.464, 'co...</td>\n",
              "      <td>0.9865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>foundation truly one greatest science fiction ...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.478, 'pos': 0.522, 'comp...</td>\n",
              "      <td>0.9781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>spectacular universe created issac asimov foun...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.661, 'pos': 0.245, 'co...</td>\n",
              "      <td>0.6705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>think book read every fanatic science fictioni...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  matter many times read book impossible get tir...   \n",
              "1        1  avid scifi fan ive read many books genere foun...   \n",
              "2        2  foundation truly one greatest science fiction ...   \n",
              "3        3  spectacular universe created issac asimov foun...   \n",
              "4        4  think book read every fanatic science fictioni...   \n",
              "\n",
              "                                              scores  compound_sentiment  \n",
              "0  {'neg': 0.075, 'neu': 0.517, 'pos': 0.408, 'co...              0.9169  \n",
              "1  {'neg': 0.066, 'neu': 0.471, 'pos': 0.464, 'co...              0.9865  \n",
              "2  {'neg': 0.0, 'neu': 0.478, 'pos': 0.522, 'comp...              0.9781  \n",
              "3  {'neg': 0.094, 'neu': 0.661, 'pos': 0.245, 'co...              0.6705  \n",
              "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...              0.0000  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['compound_sentiment']=df_reduced['scores'].apply(lambda score_dict:score_dict['compound'])\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_reduced['sentiment']=''\n",
        "# df_reduced.loc[df_reduced.compound>0,'sentiment']='POS'\n",
        "# df_reduced.loc[df_reduced.compound==0,'sentiment']='NEUTRAL'\n",
        "# df_reduced.loc[df_reduced.compound<0,'sentiment']='NEG'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93684</th>\n",
              "      <td>93684</td>\n",
              "      <td>book vein path daggers jordans eighth definite...</td>\n",
              "      <td>0.9810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201949</th>\n",
              "      <td>201949</td>\n",
              "      <td>ladies gentlemen reviewed tolles latest one st...</td>\n",
              "      <td>0.9118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243796</th>\n",
              "      <td>243796</td>\n",
              "      <td>one books elite bounce category  bounced wall ...</td>\n",
              "      <td>-0.9453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192625</th>\n",
              "      <td>192625</td>\n",
              "      <td>unlike &amp;quot;as driven leaf&amp;quot; statements t...</td>\n",
              "      <td>0.9873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48531</th>\n",
              "      <td>48531</td>\n",
              "      <td>book mormon one books read again every time re...</td>\n",
              "      <td>0.0736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306893</th>\n",
              "      <td>306893</td>\n",
              "      <td>jane eyre wonderful story womans struggle surv...</td>\n",
              "      <td>0.9246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135078</th>\n",
              "      <td>135078</td>\n",
              "      <td>thoughts trilogy correct im wrong said posts w...</td>\n",
              "      <td>0.2960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2764</th>\n",
              "      <td>2764</td>\n",
              "      <td>ill admit book starts sorta slow get  pages it...</td>\n",
              "      <td>0.8591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12503</th>\n",
              "      <td>12503</td>\n",
              "      <td>books made movie book great far better movie h...</td>\n",
              "      <td>0.8687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317431</th>\n",
              "      <td>317431</td>\n",
              "      <td>bush dodged draft? kind lunatic would think cl...</td>\n",
              "      <td>-0.7319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                         text_clean  \\\n",
              "93684     93684  book vein path daggers jordans eighth definite...   \n",
              "201949   201949  ladies gentlemen reviewed tolles latest one st...   \n",
              "243796   243796  one books elite bounce category  bounced wall ...   \n",
              "192625   192625  unlike &quot;as driven leaf&quot; statements t...   \n",
              "48531     48531  book mormon one books read again every time re...   \n",
              "306893   306893  jane eyre wonderful story womans struggle surv...   \n",
              "135078   135078  thoughts trilogy correct im wrong said posts w...   \n",
              "2764       2764  ill admit book starts sorta slow get  pages it...   \n",
              "12503     12503  books made movie book great far better movie h...   \n",
              "317431   317431  bush dodged draft? kind lunatic would think cl...   \n",
              "\n",
              "        compound_sentiment  \n",
              "93684               0.9810  \n",
              "201949              0.9118  \n",
              "243796             -0.9453  \n",
              "192625              0.9873  \n",
              "48531               0.0736  \n",
              "306893              0.9246  \n",
              "135078              0.2960  \n",
              "2764                0.8591  \n",
              "12503               0.8687  \n",
              "317431             -0.7319  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced = df_reduced.drop(['scores'], axis=1)\n",
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reduced.to_csv('../data/processed/df_reduced_with_sentiment.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
