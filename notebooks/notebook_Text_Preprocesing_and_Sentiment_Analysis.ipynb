{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZZpOHZExcMw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arnaldochm/Documents/BootCamp_DataScience/Final_Project/final_project_nlp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-11-04 18:40:31.148707: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-04 18:40:31.157522: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-04 18:40:31.227373: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-04 18:40:31.228384: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-04 18:40:32.140834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Step 0. Load libraries and custom modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "# ------------  PREPROCESING -------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "#-------------- TRANSFORMERS --------------\n",
        "import transformers\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "from transformers import Conversation\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx0-j5xbxcMx",
        "outputId": "8fde96c4-b40b-4503-91f2-83b620613f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 502041 entries, 0 to 502040\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  502041 non-null  int64 \n",
            " 1   num_row     502041 non-null  int64 \n",
            " 2   text        502041 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 11.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df_reduced = pd.read_csv('../data/processed/df_reduced.csv')\n",
        "df_reduced.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hI-V-oHmxcMy"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['Unnamed: 0'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AJnhviSgxcMy",
        "outputId": "642af037-c9b0-43f7-f053-e1bd64234f83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>245786</th>\n",
              "      <td>245786</td>\n",
              "      <td>WHAT'S NOT TO LOVE?My love of this Bible began...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173234</th>\n",
              "      <td>173234</td>\n",
              "      <td>I had this book for a Spanish literature cours...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300431</th>\n",
              "      <td>300431</td>\n",
              "      <td>55000 miles of trying to heal. What is one to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455899</th>\n",
              "      <td>455899</td>\n",
              "      <td>The book presents a unique opportunity for rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224031</th>\n",
              "      <td>224031</td>\n",
              "      <td>I concur with Mojo's review and thanks for the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351667</th>\n",
              "      <td>351667</td>\n",
              "      <td>Ever wonder how automobiles get that perfect l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252926</th>\n",
              "      <td>252926</td>\n",
              "      <td>This book is great for many first time parents...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353309</th>\n",
              "      <td>353309</td>\n",
              "      <td>Have to agree some of the others reviews, this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13853</th>\n",
              "      <td>13853</td>\n",
              "      <td>Chloe Rand seems to have the perfect life. She...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409548</th>\n",
              "      <td>409548</td>\n",
              "      <td>Excellent book for JAR-66 Module 7 and A&amp;amp;P...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                               text\n",
              "245786   245786  WHAT'S NOT TO LOVE?My love of this Bible began...\n",
              "173234   173234  I had this book for a Spanish literature cours...\n",
              "300431   300431  55000 miles of trying to heal. What is one to ...\n",
              "455899   455899  The book presents a unique opportunity for rea...\n",
              "224031   224031  I concur with Mojo's review and thanks for the...\n",
              "351667   351667  Ever wonder how automobiles get that perfect l...\n",
              "252926   252926  This book is great for many first time parents...\n",
              "353309   353309  Have to agree some of the others reviews, this...\n",
              "13853     13853  Chloe Rand seems to have the perfect life. She...\n",
              "409548   409548  Excellent book for JAR-66 Module 7 and A&amp;P..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QLcrOVQCSvV",
        "outputId": "56ad309f-5ba2-4ed4-9720-2c7fafdebe70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TnFxeo9YCd1n"
      },
      "outputs": [],
      "source": [
        "def clean_stopwords(text: str,stop_dict: dict)->str:\n",
        "    if text is not None:\n",
        "        words = text.split()\n",
        "        words_clean = []\n",
        "        for word in words:\n",
        "            if word not in stop_dict:\n",
        "                words_clean.append(word)\n",
        "        result = ' '.join(words_clean)\n",
        "    else:\n",
        "        result = None\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OaZQCL1hCHjS"
      },
      "outputs": [],
      "source": [
        "# 3.10 Process text to extract stopwords\n",
        "df_reduced['text_clean'] = df_reduced['text'].str.lower()\n",
        "stop_dict = stopwords.words('english')\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].apply(lambda x: clean_stopwords(x, stop_dict = stop_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z8J38661CzTx"
      },
      "outputs": [],
      "source": [
        "# 3.12 Extract special characters\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'''[!.,():\\-%$/'\"‘]''', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rObXY_twC7C3"
      },
      "outputs": [],
      "source": [
        "# 3.13 Extract numbers\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'[\\d]+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UDVhJZmmJWPM"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['text'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lvYNEGJPDjLI",
        "outputId": "b9b25394-1a28-4218-c34f-37341d001f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>someone know receives diagnosis prostate cance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>simple point chalk full information herbs uses...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>read book day &amp; half interesting reading belie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>bought book biological anthropology class text...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>slaughterhouse  slaughterhouse five childrens ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean\n",
              "0        0  pretty good book clear content say something r...\n",
              "1        1  terry pratchetts first novel the carpet people...\n",
              "2        2  must around  capable artist basil hallward bri...\n",
              "3        3  first read book early teens reread fourth time...\n",
              "4        4  patrick kelsey learns woman replace retired co...\n",
              "5        5  someone know receives diagnosis prostate cance...\n",
              "6        6  simple point chalk full information herbs uses...\n",
              "7        7  read book day & half interesting reading belie...\n",
              "8        8  bought book biological anthropology class text...\n",
              "9        9  slaughterhouse  slaughterhouse five childrens ..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3.14 See the results\n",
        "df_reduced.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaderSentimentAnalyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.162, 'neu': 0.568, 'pos': 0.27, 'compound': 0.7579}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vaderSentimentAnalyzer.polarity_scores(df_reduced.iloc[67]['text_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "      <td>{'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "      <td>{'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "      <td>{'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "      <td>{'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "      <td>{'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  pretty good book clear content say something r...   \n",
              "1        1  terry pratchetts first novel the carpet people...   \n",
              "2        2  must around  capable artist basil hallward bri...   \n",
              "3        3  first read book early teens reread fourth time...   \n",
              "4        4  patrick kelsey learns woman replace retired co...   \n",
              "\n",
              "                                              scores  \n",
              "0  {'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...  \n",
              "1  {'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...  \n",
              "2  {'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...  \n",
              "3  {'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...  \n",
              "4  {'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['scores']=df_reduced['text_clean'].apply(lambda body: vaderSentimentAnalyzer.polarity_scores(str(body)))\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "      <td>{'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...</td>\n",
              "      <td>0.9948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "      <td>{'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...</td>\n",
              "      <td>0.9823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "      <td>{'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...</td>\n",
              "      <td>0.9970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "      <td>{'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...</td>\n",
              "      <td>0.1280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "      <td>{'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...</td>\n",
              "      <td>0.4624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  pretty good book clear content say something r...   \n",
              "1        1  terry pratchetts first novel the carpet people...   \n",
              "2        2  must around  capable artist basil hallward bri...   \n",
              "3        3  first read book early teens reread fourth time...   \n",
              "4        4  patrick kelsey learns woman replace retired co...   \n",
              "\n",
              "                                              scores  compound_sentiment  \n",
              "0  {'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...              0.9948  \n",
              "1  {'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...              0.9823  \n",
              "2  {'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...              0.9970  \n",
              "3  {'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...              0.1280  \n",
              "4  {'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...              0.4624  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['compound_sentiment']=df_reduced['scores'].apply(lambda score_dict:score_dict['compound'])\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>455827</th>\n",
              "      <td>455827</td>\n",
              "      <td>book one carry long time offers many opportuni...</td>\n",
              "      <td>0.9834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289810</th>\n",
              "      <td>289810</td>\n",
              "      <td>husband loves book recipes fry anything think ...</td>\n",
              "      <td>0.8225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226952</th>\n",
              "      <td>226952</td>\n",
              "      <td>somewhat top author sticks pins lot hypocritic...</td>\n",
              "      <td>0.2748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4832</th>\n",
              "      <td>4832</td>\n",
              "      <td>one best books read want see happens countries...</td>\n",
              "      <td>0.9360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457118</th>\n",
              "      <td>457118</td>\n",
              "      <td>another wonderful leigh koslow mystery easily ...</td>\n",
              "      <td>0.8020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379972</th>\n",
              "      <td>379972</td>\n",
              "      <td>demian hesse relates spiritual struggle one em...</td>\n",
              "      <td>0.9956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314349</th>\n",
              "      <td>314349</td>\n",
              "      <td>thoroughly enjoyed version three little pigs w...</td>\n",
              "      <td>0.9302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282052</th>\n",
              "      <td>282052</td>\n",
              "      <td>ohim sorry rate book ? probably mentten probab...</td>\n",
              "      <td>0.9495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263028</th>\n",
              "      <td>263028</td>\n",
              "      <td>gospel luke acts apostles jointly called lukea...</td>\n",
              "      <td>0.9838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404561</th>\n",
              "      <td>404561</td>\n",
              "      <td>is course admirable roth takes great effort wr...</td>\n",
              "      <td>0.9907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                         text_clean  \\\n",
              "455827   455827  book one carry long time offers many opportuni...   \n",
              "289810   289810  husband loves book recipes fry anything think ...   \n",
              "226952   226952  somewhat top author sticks pins lot hypocritic...   \n",
              "4832       4832  one best books read want see happens countries...   \n",
              "457118   457118  another wonderful leigh koslow mystery easily ...   \n",
              "379972   379972  demian hesse relates spiritual struggle one em...   \n",
              "314349   314349  thoroughly enjoyed version three little pigs w...   \n",
              "282052   282052  ohim sorry rate book ? probably mentten probab...   \n",
              "263028   263028  gospel luke acts apostles jointly called lukea...   \n",
              "404561   404561  is course admirable roth takes great effort wr...   \n",
              "\n",
              "        compound_sentiment  \n",
              "455827              0.9834  \n",
              "289810              0.8225  \n",
              "226952              0.2748  \n",
              "4832                0.9360  \n",
              "457118              0.8020  \n",
              "379972              0.9956  \n",
              "314349              0.9302  \n",
              "282052              0.9495  \n",
              "263028              0.9838  \n",
              "404561              0.9907  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced = df_reduced.drop(['scores'], axis=1)\n",
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reduced.to_csv('../data/processed/df_reduced_with_sentiment.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
