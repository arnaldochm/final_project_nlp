{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZZpOHZExcMw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arnaldochm/Documents/BootCamp_DataScience/Final_Project/final_project_nlp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-10-31 20:21:15.559192: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-10-31 20:21:15.561149: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-31 20:21:15.597357: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-31 20:21:15.599141: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-31 20:21:16.390705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Step 0. Load libraries and custom modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "# ------------  PREPROCESING -------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "#-------------- TRANSFORMERS --------------\n",
        "import transformers\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "from transformers import Conversation\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx0-j5xbxcMx",
        "outputId": "8fde96c4-b40b-4503-91f2-83b620613f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 339619 entries, 0 to 339618\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  339619 non-null  int64 \n",
            " 1   num_row     339619 non-null  int64 \n",
            " 2   text        339619 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 7.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df_reduced = pd.read_csv('../data/processed/df_reduced.csv')\n",
        "df_reduced.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hI-V-oHmxcMy"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['Unnamed: 0'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AJnhviSgxcMy",
        "outputId": "642af037-c9b0-43f7-f053-e1bd64234f83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64331</th>\n",
              "      <td>64331</td>\n",
              "      <td>A must read for the adventure seeker and wilde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328380</th>\n",
              "      <td>328380</td>\n",
              "      <td>The Lord of the Rings provides entertainment f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300373</th>\n",
              "      <td>300373</td>\n",
              "      <td>Loved this book and reminded me that there rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255257</th>\n",
              "      <td>255257</td>\n",
              "      <td>Wuthering Heights is the name of the house whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106516</th>\n",
              "      <td>106516</td>\n",
              "      <td>I think that this is a great book. There is on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136036</th>\n",
              "      <td>136036</td>\n",
              "      <td>Beautifully written,must read CHILDRENS classi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83763</th>\n",
              "      <td>83763</td>\n",
              "      <td>This book is quite different from the movies I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219627</th>\n",
              "      <td>219627</td>\n",
              "      <td>To the reviewer known as &amp;quot;Kyle,&amp;quot; per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95310</th>\n",
              "      <td>95310</td>\n",
              "      <td>Sorry, but this book didn't really have any re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225174</th>\n",
              "      <td>225174</td>\n",
              "      <td>I read this book 12 years ago in high school, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                               text\n",
              "64331     64331  A must read for the adventure seeker and wilde...\n",
              "328380   328380  The Lord of the Rings provides entertainment f...\n",
              "300373   300373  Loved this book and reminded me that there rea...\n",
              "255257   255257  Wuthering Heights is the name of the house whe...\n",
              "106516   106516  I think that this is a great book. There is on...\n",
              "136036   136036  Beautifully written,must read CHILDRENS classi...\n",
              "83763     83763  This book is quite different from the movies I...\n",
              "219627   219627  To the reviewer known as &quot;Kyle,&quot; per...\n",
              "95310     95310  Sorry, but this book didn't really have any re...\n",
              "225174   225174  I read this book 12 years ago in high school, ..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QLcrOVQCSvV",
        "outputId": "56ad309f-5ba2-4ed4-9720-2c7fafdebe70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TnFxeo9YCd1n"
      },
      "outputs": [],
      "source": [
        "def clean_stopwords(text: str,stop_dict: dict)->str:\n",
        "    if text is not None:\n",
        "        words = text.split()\n",
        "        words_clean = []\n",
        "        for word in words:\n",
        "            if word not in stop_dict:\n",
        "                words_clean.append(word)\n",
        "        result = ' '.join(words_clean)\n",
        "    else:\n",
        "        result = None\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OaZQCL1hCHjS"
      },
      "outputs": [],
      "source": [
        "# 3.10 Process text to extract stopwords\n",
        "df_reduced['text_clean'] = df_reduced['text'].str.lower()\n",
        "stop_dict = stopwords.words('english')\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].apply(lambda x: clean_stopwords(x, stop_dict = stop_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z8J38661CzTx"
      },
      "outputs": [],
      "source": [
        "# 3.12 Extract special characters\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'''[!.,():\\-%$/'\"â€˜]''', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rObXY_twC7C3"
      },
      "outputs": [],
      "source": [
        "# 3.13 Extract numbers\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'[\\d]+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UDVhJZmmJWPM"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['text'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lvYNEGJPDjLI",
        "outputId": "b9b25394-1a28-4218-c34f-37341d001f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>matter many times read book impossible get tir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>avid scifi fan ive read many books genere foun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>foundation truly one greatest science fiction ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>spectacular universe created issac asimov foun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>think book read every fanatic science fictioni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>think isaac must robot human could possibly am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>foundation series still classic must read ever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>foundation novels great pleasureto read surpri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>foundation nut given  issac asimovs foundatino...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>one asimovs early masterpieces however would r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean\n",
              "0        0  matter many times read book impossible get tir...\n",
              "1        1  avid scifi fan ive read many books genere foun...\n",
              "2        2  foundation truly one greatest science fiction ...\n",
              "3        3  spectacular universe created issac asimov foun...\n",
              "4        4  think book read every fanatic science fictioni...\n",
              "5        5  think isaac must robot human could possibly am...\n",
              "6        6  foundation series still classic must read ever...\n",
              "7        7  foundation novels great pleasureto read surpri...\n",
              "8        8  foundation nut given  issac asimovs foundatino...\n",
              "9        9  one asimovs early masterpieces however would r..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3.14 See the results\n",
        "df_reduced.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaderSentimentAnalyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.057, 'neu': 0.657, 'pos': 0.286, 'compound': 0.9953}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vaderSentimentAnalyzer.polarity_scores(df_reduced.iloc[67]['text_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>matter many times read book impossible get tir...</td>\n",
              "      <td>{'neg': 0.075, 'neu': 0.517, 'pos': 0.408, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>avid scifi fan ive read many books genere foun...</td>\n",
              "      <td>{'neg': 0.066, 'neu': 0.471, 'pos': 0.464, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>foundation truly one greatest science fiction ...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.478, 'pos': 0.522, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>spectacular universe created issac asimov foun...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.661, 'pos': 0.245, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>think book read every fanatic science fictioni...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  matter many times read book impossible get tir...   \n",
              "1        1  avid scifi fan ive read many books genere foun...   \n",
              "2        2  foundation truly one greatest science fiction ...   \n",
              "3        3  spectacular universe created issac asimov foun...   \n",
              "4        4  think book read every fanatic science fictioni...   \n",
              "\n",
              "                                              scores  \n",
              "0  {'neg': 0.075, 'neu': 0.517, 'pos': 0.408, 'co...  \n",
              "1  {'neg': 0.066, 'neu': 0.471, 'pos': 0.464, 'co...  \n",
              "2  {'neg': 0.0, 'neu': 0.478, 'pos': 0.522, 'comp...  \n",
              "3  {'neg': 0.094, 'neu': 0.661, 'pos': 0.245, 'co...  \n",
              "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['scores']=df_reduced['text_clean'].apply(lambda body: vaderSentimentAnalyzer.polarity_scores(str(body)))\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>matter many times read book impossible get tir...</td>\n",
              "      <td>{'neg': 0.075, 'neu': 0.517, 'pos': 0.408, 'co...</td>\n",
              "      <td>0.9169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>avid scifi fan ive read many books genere foun...</td>\n",
              "      <td>{'neg': 0.066, 'neu': 0.471, 'pos': 0.464, 'co...</td>\n",
              "      <td>0.9865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>foundation truly one greatest science fiction ...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.478, 'pos': 0.522, 'comp...</td>\n",
              "      <td>0.9781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>spectacular universe created issac asimov foun...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.661, 'pos': 0.245, 'co...</td>\n",
              "      <td>0.6705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>think book read every fanatic science fictioni...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  matter many times read book impossible get tir...   \n",
              "1        1  avid scifi fan ive read many books genere foun...   \n",
              "2        2  foundation truly one greatest science fiction ...   \n",
              "3        3  spectacular universe created issac asimov foun...   \n",
              "4        4  think book read every fanatic science fictioni...   \n",
              "\n",
              "                                              scores  compound_sentiment  \n",
              "0  {'neg': 0.075, 'neu': 0.517, 'pos': 0.408, 'co...              0.9169  \n",
              "1  {'neg': 0.066, 'neu': 0.471, 'pos': 0.464, 'co...              0.9865  \n",
              "2  {'neg': 0.0, 'neu': 0.478, 'pos': 0.522, 'comp...              0.9781  \n",
              "3  {'neg': 0.094, 'neu': 0.661, 'pos': 0.245, 'co...              0.6705  \n",
              "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...              0.0000  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['compound_sentiment']=df_reduced['scores'].apply(lambda score_dict:score_dict['compound'])\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_reduced['sentiment']=''\n",
        "# df_reduced.loc[df_reduced.compound>0,'sentiment']='POS'\n",
        "# df_reduced.loc[df_reduced.compound==0,'sentiment']='NEUTRAL'\n",
        "# df_reduced.loc[df_reduced.compound<0,'sentiment']='NEG'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163514</th>\n",
              "      <td>163514</td>\n",
              "      <td>reading new wwii novel triumph glory reminded ...</td>\n",
              "      <td>0.9648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77664</th>\n",
              "      <td>77664</td>\n",
              "      <td>first read &amp;quot;the lord rings&amp;quot; science ...</td>\n",
              "      <td>0.9727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285929</th>\n",
              "      <td>285929</td>\n",
              "      <td>read class whole book boring end worth it</td>\n",
              "      <td>-0.1027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21819</th>\n",
              "      <td>21819</td>\n",
              "      <td>ugh adults kids book people sure beginnings li...</td>\n",
              "      <td>0.7454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316334</th>\n",
              "      <td>316334</td>\n",
              "      <td>example continuing grudge made smear campaign ...</td>\n",
              "      <td>-0.2914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257719</th>\n",
              "      <td>257719</td>\n",
              "      <td>book surpirsed me way many &amp;quot;classics&amp;quot...</td>\n",
              "      <td>0.6908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61090</th>\n",
              "      <td>61090</td>\n",
              "      <td>heard lot book finally chance read it definite...</td>\n",
              "      <td>0.9476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133783</th>\n",
              "      <td>133783</td>\n",
              "      <td>book interesting history book takes place unit...</td>\n",
              "      <td>-0.7184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131030</th>\n",
              "      <td>131030</td>\n",
              "      <td>since listened angelas ashes narrated author f...</td>\n",
              "      <td>0.9042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151888</th>\n",
              "      <td>151888</td>\n",
              "      <td>wait dive book first &amp;quot;fun&amp;quot; novel ive...</td>\n",
              "      <td>0.7430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                         text_clean  \\\n",
              "163514   163514  reading new wwii novel triumph glory reminded ...   \n",
              "77664     77664  first read &quot;the lord rings&quot; science ...   \n",
              "285929   285929          read class whole book boring end worth it   \n",
              "21819     21819  ugh adults kids book people sure beginnings li...   \n",
              "316334   316334  example continuing grudge made smear campaign ...   \n",
              "257719   257719  book surpirsed me way many &quot;classics&quot...   \n",
              "61090     61090  heard lot book finally chance read it definite...   \n",
              "133783   133783  book interesting history book takes place unit...   \n",
              "131030   131030  since listened angelas ashes narrated author f...   \n",
              "151888   151888  wait dive book first &quot;fun&quot; novel ive...   \n",
              "\n",
              "        compound_sentiment  \n",
              "163514              0.9648  \n",
              "77664               0.9727  \n",
              "285929             -0.1027  \n",
              "21819               0.7454  \n",
              "316334             -0.2914  \n",
              "257719              0.6908  \n",
              "61090               0.9476  \n",
              "133783             -0.7184  \n",
              "131030              0.9042  \n",
              "151888              0.7430  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced = df_reduced.drop(['scores'], axis=1)\n",
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reduced.to_csv('../data/processed/df_reduced_with_sentiment.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
