{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZZpOHZExcMw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arnaldochm/Documents/BootCamp_DataScience/Final_Project/final_project_nlp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-11-07 21:05:39.703581: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-07 21:05:39.705614: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-07 21:05:39.747468: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-07 21:05:39.748737: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-07 21:05:40.716450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Step 0. Load libraries and custom modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "# ------------  PREPROCESING -------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "#-------------- TRANSFORMERS --------------\n",
        "import transformers\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "from transformers import Conversation\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx0-j5xbxcMx",
        "outputId": "8fde96c4-b40b-4503-91f2-83b620613f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15738 entries, 0 to 15737\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  15738 non-null  int64 \n",
            " 1   num_row     15738 non-null  int64 \n",
            " 2   text        15738 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 369.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df_reduced = pd.read_csv('../data/processed/df_reduced.csv')\n",
        "df_reduced.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hI-V-oHmxcMy"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['Unnamed: 0'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AJnhviSgxcMy",
        "outputId": "642af037-c9b0-43f7-f053-e1bd64234f83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3627</th>\n",
              "      <td>3627</td>\n",
              "      <td>I got this book as a gift and I am in LOVE wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3966</th>\n",
              "      <td>3966</td>\n",
              "      <td>I was very dissapointed with every Kevin Hogan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15609</th>\n",
              "      <td>15609</td>\n",
              "      <td>Working with the Law is a very insightful book...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10131</th>\n",
              "      <td>10131</td>\n",
              "      <td>This book examines the lives of Albert Einstei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>1194</td>\n",
              "      <td>Being a baseball fan and having visited Cooper...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1837</th>\n",
              "      <td>1837</td>\n",
              "      <td>Whew... it's over.I think its obvious these re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1792</th>\n",
              "      <td>1792</td>\n",
              "      <td>As a Northwesterner, I was interested in readi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10174</th>\n",
              "      <td>10174</td>\n",
              "      <td>loved it was an action packed very well writte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15453</th>\n",
              "      <td>15453</td>\n",
              "      <td>That is, by reading Mr. Clarke's new novel! Ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5466</th>\n",
              "      <td>5466</td>\n",
              "      <td>Written in 1922, this biography shows a lot of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       num_row                                               text\n",
              "3627      3627  I got this book as a gift and I am in LOVE wit...\n",
              "3966      3966  I was very dissapointed with every Kevin Hogan...\n",
              "15609    15609  Working with the Law is a very insightful book...\n",
              "10131    10131  This book examines the lives of Albert Einstei...\n",
              "1194      1194  Being a baseball fan and having visited Cooper...\n",
              "1837      1837  Whew... it's over.I think its obvious these re...\n",
              "1792      1792  As a Northwesterner, I was interested in readi...\n",
              "10174    10174  loved it was an action packed very well writte...\n",
              "15453    15453  That is, by reading Mr. Clarke's new novel! Ab...\n",
              "5466      5466  Written in 1922, this biography shows a lot of..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TnFxeo9YCd1n"
      },
      "outputs": [],
      "source": [
        "# def clean_stopwords(text: str,stop_dict: dict)->str:\n",
        "#     if text is not None:\n",
        "#         words = text.split()\n",
        "#         words_clean = []\n",
        "#         for word in words:\n",
        "#             if word not in stop_dict:\n",
        "#                 words_clean.append(word)\n",
        "#         result = ' '.join(words_clean)\n",
        "#     else:\n",
        "#         result = None\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OaZQCL1hCHjS"
      },
      "outputs": [],
      "source": [
        "# 3.10 Text To Lower\n",
        "df_reduced['text_clean'] = df_reduced['text'].str.lower()\n",
        "# 3.12 Extract special characters and numbers\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'[^a-z]', ' ', regex=True)\n",
        "# 3.13 Extract numbers\n",
        "# df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'[\\d]+', '', regex=True)\n",
        "# 3.14 #Change multiple white spaces to a single white space\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'\\s+',' ',regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Z8J38661CzTx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# 3.15 Lemmatize Text and removing Stopwords\n",
        "\n",
        "download(\"wordnet\")\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rObXY_twC7C3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "download(\"stopwords\")\n",
        "stop_words = stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lemmatize_text(words, lemmatizer = lemmatizer):\n",
        "    words = words.split(' ')\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in words]\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [word for word in tokens if len(word) > 3]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14132    else expect jonathan kellerman well continuous...\n",
              "5311     purchased modern american memoir group adult w...\n",
              "8392     enjoy michener ability create interesting fict...\n",
              "13889    received little house collection started readi...\n",
              "13096    seattle mostly native year picked book guest c...\n",
              "10084    thoroughly enjoyed reading book blackwell wond...\n",
              "9567     jastrow good reference piece describes languag...\n",
              "7182     usually slow reader take week sometimes month ...\n",
              "13778    trying level class library past year many prob...\n",
              "6343     anyone interested literary translation work ap...\n",
              "Name: text_clean, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced[\"text_clean\"] = df_reduced[\"text_clean\"].apply(lambda x: lemmatize_text(x))\n",
        "df_reduced[\"text_clean\"].sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UDVhJZmmJWPM"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['text'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lvYNEGJPDjLI",
        "outputId": "b9b25394-1a28-4218-c34f-37341d001f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>purchased book neice cruised week loved story ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>really enjoyed book several front author terri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>interesting informative spot good book read wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>must learn past history better appreciate toda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>began book high hope cover blurb sounded inter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>gary demar succeeded writing finest short actu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>first miss julia book found quite delightful b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>enjoying read assuming writes like think long ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>book simply great start reading able page page...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>hobbit written differently lord ring time much...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean\n",
              "0        0  purchased book neice cruised week loved story ...\n",
              "1        1  really enjoyed book several front author terri...\n",
              "2        2  interesting informative spot good book read wa...\n",
              "3        3  must learn past history better appreciate toda...\n",
              "4        4  began book high hope cover blurb sounded inter...\n",
              "5        5  gary demar succeeded writing finest short actu...\n",
              "6        6  first miss julia book found quite delightful b...\n",
              "7        7  enjoying read assuming writes like think long ...\n",
              "8        8  book simply great start reading able page page...\n",
              "9        9  hobbit written differently lord ring time much..."
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3.14 See the results\n",
        "df_reduced.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaderSentimentAnalyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'goethe expressed fundamental truth nothing much philosophy footnote plato plotinus year later plato eliminated platonic dabbling politics quietly separated greek mysticism emerging fundamentalism christianity became somewhat bemusedly cult figure right brian hines deal subject hugely sympathatic hope future something change time plato century close timeless truth time well according plotinus father robin'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced.iloc[67]['text_clean']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.829, 'pos': 0.171, 'compound': 0.835}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vaderSentimentAnalyzer.polarity_scores(df_reduced.iloc[67]['text_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>purchased book neice cruised week loved story ...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.647, 'pos': 0.353, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>really enjoyed book several front author terri...</td>\n",
              "      <td>{'neg': 0.116, 'neu': 0.564, 'pos': 0.32, 'com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>interesting informative spot good book read wa...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.504, 'pos': 0.496, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>must learn past history better appreciate toda...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.554, 'pos': 0.352, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>began book high hope cover blurb sounded inter...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.643, 'pos': 0.263, 'co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  purchased book neice cruised week loved story ...   \n",
              "1        1  really enjoyed book several front author terri...   \n",
              "2        2  interesting informative spot good book read wa...   \n",
              "3        3  must learn past history better appreciate toda...   \n",
              "4        4  began book high hope cover blurb sounded inter...   \n",
              "\n",
              "                                              scores  \n",
              "0  {'neg': 0.0, 'neu': 0.647, 'pos': 0.353, 'comp...  \n",
              "1  {'neg': 0.116, 'neu': 0.564, 'pos': 0.32, 'com...  \n",
              "2  {'neg': 0.0, 'neu': 0.504, 'pos': 0.496, 'comp...  \n",
              "3  {'neg': 0.094, 'neu': 0.554, 'pos': 0.352, 'co...  \n",
              "4  {'neg': 0.094, 'neu': 0.643, 'pos': 0.263, 'co...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['scores']=df_reduced['text_clean'].apply(lambda body: vaderSentimentAnalyzer.polarity_scores(str(body)))\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>purchased book neice cruised week loved story ...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.647, 'pos': 0.353, 'comp...</td>\n",
              "      <td>0.9623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>really enjoyed book several front author terri...</td>\n",
              "      <td>{'neg': 0.116, 'neu': 0.564, 'pos': 0.32, 'com...</td>\n",
              "      <td>0.9904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>interesting informative spot good book read wa...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.504, 'pos': 0.496, 'comp...</td>\n",
              "      <td>0.7096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>must learn past history better appreciate toda...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.554, 'pos': 0.352, 'co...</td>\n",
              "      <td>0.9595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>began book high hope cover blurb sounded inter...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.643, 'pos': 0.263, 'co...</td>\n",
              "      <td>0.9933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  purchased book neice cruised week loved story ...   \n",
              "1        1  really enjoyed book several front author terri...   \n",
              "2        2  interesting informative spot good book read wa...   \n",
              "3        3  must learn past history better appreciate toda...   \n",
              "4        4  began book high hope cover blurb sounded inter...   \n",
              "\n",
              "                                              scores  compound_sentiment  \n",
              "0  {'neg': 0.0, 'neu': 0.647, 'pos': 0.353, 'comp...              0.9623  \n",
              "1  {'neg': 0.116, 'neu': 0.564, 'pos': 0.32, 'com...              0.9904  \n",
              "2  {'neg': 0.0, 'neu': 0.504, 'pos': 0.496, 'comp...              0.7096  \n",
              "3  {'neg': 0.094, 'neu': 0.554, 'pos': 0.352, 'co...              0.9595  \n",
              "4  {'neg': 0.094, 'neu': 0.643, 'pos': 0.263, 'co...              0.9933  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['compound_sentiment']=df_reduced['scores'].apply(lambda score_dict:score_dict['compound'])\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8362</th>\n",
              "      <td>8362</td>\n",
              "      <td>story original unlike haunted house story feel...</td>\n",
              "      <td>0.4215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7980</th>\n",
              "      <td>7980</td>\n",
              "      <td>noted dance writer critic robert greskovic han...</td>\n",
              "      <td>0.6369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2272</th>\n",
              "      <td>2272</td>\n",
              "      <td>evaluating hobbit naturally compare later lord...</td>\n",
              "      <td>0.9916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10894</th>\n",
              "      <td>10894</td>\n",
              "      <td>professor hardwigg find note written arne sakn...</td>\n",
              "      <td>0.9169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8685</th>\n",
              "      <td>8685</td>\n",
              "      <td>read eragon young writer paolini wrote novel p...</td>\n",
              "      <td>0.9607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11962</th>\n",
              "      <td>11962</td>\n",
              "      <td>living inner city neighborhood heather gemmen ...</td>\n",
              "      <td>-0.9839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2808</th>\n",
              "      <td>2808</td>\n",
              "      <td>gayle wigglesworth left world began education ...</td>\n",
              "      <td>0.9822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9483</th>\n",
              "      <td>9483</td>\n",
              "      <td>book good delay respected right christmas perf...</td>\n",
              "      <td>0.9442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9394</th>\n",
              "      <td>9394</td>\n",
              "      <td>real winner word word captivating beginning fe...</td>\n",
              "      <td>0.9652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>943</td>\n",
              "      <td>helpful descriptive beginning experienced shri...</td>\n",
              "      <td>0.4215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       num_row                                         text_clean  \\\n",
              "8362      8362  story original unlike haunted house story feel...   \n",
              "7980      7980  noted dance writer critic robert greskovic han...   \n",
              "2272      2272  evaluating hobbit naturally compare later lord...   \n",
              "10894    10894  professor hardwigg find note written arne sakn...   \n",
              "8685      8685  read eragon young writer paolini wrote novel p...   \n",
              "11962    11962  living inner city neighborhood heather gemmen ...   \n",
              "2808      2808  gayle wigglesworth left world began education ...   \n",
              "9483      9483  book good delay respected right christmas perf...   \n",
              "9394      9394  real winner word word captivating beginning fe...   \n",
              "943        943  helpful descriptive beginning experienced shri...   \n",
              "\n",
              "       compound_sentiment  \n",
              "8362               0.4215  \n",
              "7980               0.6369  \n",
              "2272               0.9916  \n",
              "10894              0.9169  \n",
              "8685               0.9607  \n",
              "11962             -0.9839  \n",
              "2808               0.9822  \n",
              "9483               0.9442  \n",
              "9394               0.9652  \n",
              "943                0.4215  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced = df_reduced.drop(['scores'], axis=1)\n",
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reduced.to_csv('../data/processed/df_reduced_with_sentiment.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
