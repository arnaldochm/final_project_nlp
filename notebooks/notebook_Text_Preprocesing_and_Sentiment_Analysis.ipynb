{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZZpOHZExcMw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/arnaldochm/Documents/BootCamp_DataScience/Final_Project/final_project_nlp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-11-02 22:20:25.159342: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-02 22:20:25.160946: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-02 22:20:25.205655: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-11-02 22:20:25.206844: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-02 22:20:25.976642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Step 0. Load libraries and custom modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "# ------------  PREPROCESING -------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "#-------------- TRANSFORMERS --------------\n",
        "import transformers\n",
        "from transformers.pipelines import PIPELINE_REGISTRY\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "from transformers import Conversation\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx0-j5xbxcMx",
        "outputId": "8fde96c4-b40b-4503-91f2-83b620613f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 552639 entries, 0 to 552638\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  552639 non-null  int64 \n",
            " 1   num_row     552639 non-null  int64 \n",
            " 2   text        552639 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 12.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df_reduced = pd.read_csv('../data/processed/df_reduced.csv')\n",
        "df_reduced.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hI-V-oHmxcMy"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['Unnamed: 0'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "AJnhviSgxcMy",
        "outputId": "642af037-c9b0-43f7-f053-e1bd64234f83"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77540</th>\n",
              "      <td>77540</td>\n",
              "      <td>If you have already read the &amp;quot;how-to&amp;quot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495636</th>\n",
              "      <td>495636</td>\n",
              "      <td>i'm writing this a week after Obama's election...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269858</th>\n",
              "      <td>269858</td>\n",
              "      <td>One of the most eye opening books, He has grea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338976</th>\n",
              "      <td>338976</td>\n",
              "      <td>An Old Fashioned Girl begins with a teenage gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37240</th>\n",
              "      <td>37240</td>\n",
              "      <td>Ten Little Indians is a book of nine short sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441918</th>\n",
              "      <td>441918</td>\n",
              "      <td>She makes so much sense, and explains everythi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96497</th>\n",
              "      <td>96497</td>\n",
              "      <td>Amazon went over and beyond their call of duty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363219</th>\n",
              "      <td>363219</td>\n",
              "      <td>This is a wonderful book to just get lost in f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328866</th>\n",
              "      <td>328866</td>\n",
              "      <td>This is a nice little book with a motivational...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255396</th>\n",
              "      <td>255396</td>\n",
              "      <td>Besides as the diary of 1991 Pet Shop Boys Ame...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                               text\n",
              "77540     77540  If you have already read the &quot;how-to&quot...\n",
              "495636   495636  i'm writing this a week after Obama's election...\n",
              "269858   269858  One of the most eye opening books, He has grea...\n",
              "338976   338976  An Old Fashioned Girl begins with a teenage gi...\n",
              "37240     37240  Ten Little Indians is a book of nine short sto...\n",
              "441918   441918  She makes so much sense, and explains everythi...\n",
              "96497     96497  Amazon went over and beyond their call of duty...\n",
              "363219   363219  This is a wonderful book to just get lost in f...\n",
              "328866   328866  This is a nice little book with a motivational...\n",
              "255396   255396  Besides as the diary of 1991 Pet Shop Boys Ame..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QLcrOVQCSvV",
        "outputId": "56ad309f-5ba2-4ed4-9720-2c7fafdebe70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TnFxeo9YCd1n"
      },
      "outputs": [],
      "source": [
        "def clean_stopwords(text: str,stop_dict: dict)->str:\n",
        "    if text is not None:\n",
        "        words = text.split()\n",
        "        words_clean = []\n",
        "        for word in words:\n",
        "            if word not in stop_dict:\n",
        "                words_clean.append(word)\n",
        "        result = ' '.join(words_clean)\n",
        "    else:\n",
        "        result = None\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OaZQCL1hCHjS"
      },
      "outputs": [],
      "source": [
        "# 3.10 Process text to extract stopwords\n",
        "df_reduced['text_clean'] = df_reduced['text'].str.lower()\n",
        "stop_dict = stopwords.words('english')\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].apply(lambda x: clean_stopwords(x, stop_dict = stop_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z8J38661CzTx"
      },
      "outputs": [],
      "source": [
        "# 3.12 Extract special characters\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'''[!.,():\\-%$/'\"â€˜]''', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rObXY_twC7C3"
      },
      "outputs": [],
      "source": [
        "# 3.13 Extract numbers\n",
        "df_reduced['text_clean'] = df_reduced['text_clean'].str.replace(r'[\\d]+', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UDVhJZmmJWPM"
      },
      "outputs": [],
      "source": [
        "df_reduced = df_reduced.drop(['text'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lvYNEGJPDjLI",
        "outputId": "b9b25394-1a28-4218-c34f-37341d001f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>someone know receives diagnosis prostate cance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>simple point chalk full information herbs uses...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>read book day &amp; half interesting reading belie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>bought book biological anthropology class text...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>slaughterhouse  slaughterhouse five childrens ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean\n",
              "0        0  pretty good book clear content say something r...\n",
              "1        1  terry pratchetts first novel the carpet people...\n",
              "2        2  must around  capable artist basil hallward bri...\n",
              "3        3  first read book early teens reread fourth time...\n",
              "4        4  patrick kelsey learns woman replace retired co...\n",
              "5        5  someone know receives diagnosis prostate cance...\n",
              "6        6  simple point chalk full information herbs uses...\n",
              "7        7  read book day & half interesting reading belie...\n",
              "8        8  bought book biological anthropology class text...\n",
              "9        9  slaughterhouse  slaughterhouse five childrens ..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3.14 See the results\n",
        "df_reduced.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/arnaldochm/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vaderSentimentAnalyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.162, 'neu': 0.568, 'pos': 0.27, 'compound': 0.7579}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vaderSentimentAnalyzer.polarity_scores(df_reduced.iloc[67]['text_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "      <td>{'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "      <td>{'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "      <td>{'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "      <td>{'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "      <td>{'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  pretty good book clear content say something r...   \n",
              "1        1  terry pratchetts first novel the carpet people...   \n",
              "2        2  must around  capable artist basil hallward bri...   \n",
              "3        3  first read book early teens reread fourth time...   \n",
              "4        4  patrick kelsey learns woman replace retired co...   \n",
              "\n",
              "                                              scores  \n",
              "0  {'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...  \n",
              "1  {'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...  \n",
              "2  {'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...  \n",
              "3  {'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...  \n",
              "4  {'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['scores']=df_reduced['text_clean'].apply(lambda body: vaderSentimentAnalyzer.polarity_scores(str(body)))\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pretty good book clear content say something r...</td>\n",
              "      <td>{'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...</td>\n",
              "      <td>0.9948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>terry pratchetts first novel the carpet people...</td>\n",
              "      <td>{'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...</td>\n",
              "      <td>0.9823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>must around  capable artist basil hallward bri...</td>\n",
              "      <td>{'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...</td>\n",
              "      <td>0.9970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>first read book early teens reread fourth time...</td>\n",
              "      <td>{'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...</td>\n",
              "      <td>0.1280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>patrick kelsey learns woman replace retired co...</td>\n",
              "      <td>{'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...</td>\n",
              "      <td>0.4624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_row                                         text_clean  \\\n",
              "0        0  pretty good book clear content say something r...   \n",
              "1        1  terry pratchetts first novel the carpet people...   \n",
              "2        2  must around  capable artist basil hallward bri...   \n",
              "3        3  first read book early teens reread fourth time...   \n",
              "4        4  patrick kelsey learns woman replace retired co...   \n",
              "\n",
              "                                              scores  compound_sentiment  \n",
              "0  {'neg': 0.076, 'neu': 0.45, 'pos': 0.474, 'com...              0.9948  \n",
              "1  {'neg': 0.071, 'neu': 0.776, 'pos': 0.153, 'co...              0.9823  \n",
              "2  {'neg': 0.119, 'neu': 0.642, 'pos': 0.24, 'com...              0.9970  \n",
              "3  {'neg': 0.146, 'neu': 0.699, 'pos': 0.154, 'co...              0.1280  \n",
              "4  {'neg': 0.158, 'neu': 0.621, 'pos': 0.221, 'co...              0.4624  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced['compound_sentiment']=df_reduced['scores'].apply(lambda score_dict:score_dict['compound'])\n",
        "df_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_reduced['sentiment']=''\n",
        "# df_reduced.loc[df_reduced.compound>0,'sentiment']='POS'\n",
        "# df_reduced.loc[df_reduced.compound==0,'sentiment']='NEUTRAL'\n",
        "# df_reduced.loc[df_reduced.compound<0,'sentiment']='NEG'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_row</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>compound_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>407104</th>\n",
              "      <td>407104</td>\n",
              "      <td>content straightforward easy grasp presented w...</td>\n",
              "      <td>0.8316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339118</th>\n",
              "      <td>339118</td>\n",
              "      <td>pretty good wake call failed math portion tabe...</td>\n",
              "      <td>0.7778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240305</th>\n",
              "      <td>240305</td>\n",
              "      <td>book quite informative terrible time american ...</td>\n",
              "      <td>-0.4902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18080</th>\n",
              "      <td>18080</td>\n",
              "      <td>far worst series series reread start finish im...</td>\n",
              "      <td>-0.6249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450411</th>\n",
              "      <td>450411</td>\n",
              "      <td>mysterious computer hacker named vespers broke...</td>\n",
              "      <td>0.2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242353</th>\n",
              "      <td>242353</td>\n",
              "      <td>biscuit bliss  foolproof recipes fresh fluffy ...</td>\n",
              "      <td>0.9886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64400</th>\n",
              "      <td>64400</td>\n",
              "      <td>trudged book middle school use dictionary ever...</td>\n",
              "      <td>0.5367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175099</th>\n",
              "      <td>175099</td>\n",
              "      <td>mercedes done again books valdemar best everyb...</td>\n",
              "      <td>0.9403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402408</th>\n",
              "      <td>402408</td>\n",
              "      <td>stunning recollection new york city rapidly di...</td>\n",
              "      <td>0.8176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387598</th>\n",
              "      <td>387598</td>\n",
              "      <td>trying read book last two months although stor...</td>\n",
              "      <td>-0.4087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        num_row                                         text_clean  \\\n",
              "407104   407104  content straightforward easy grasp presented w...   \n",
              "339118   339118  pretty good wake call failed math portion tabe...   \n",
              "240305   240305  book quite informative terrible time american ...   \n",
              "18080     18080  far worst series series reread start finish im...   \n",
              "450411   450411  mysterious computer hacker named vespers broke...   \n",
              "242353   242353  biscuit bliss  foolproof recipes fresh fluffy ...   \n",
              "64400     64400  trudged book middle school use dictionary ever...   \n",
              "175099   175099  mercedes done again books valdemar best everyb...   \n",
              "402408   402408  stunning recollection new york city rapidly di...   \n",
              "387598   387598  trying read book last two months although stor...   \n",
              "\n",
              "        compound_sentiment  \n",
              "407104              0.8316  \n",
              "339118              0.7778  \n",
              "240305             -0.4902  \n",
              "18080              -0.6249  \n",
              "450411              0.2006  \n",
              "242353              0.9886  \n",
              "64400               0.5367  \n",
              "175099              0.9403  \n",
              "402408              0.8176  \n",
              "387598             -0.4087  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reduced = df_reduced.drop(['scores'], axis=1)\n",
        "df_reduced.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_reduced.to_csv('../data/processed/df_reduced_with_sentiment.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
